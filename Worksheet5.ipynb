{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def train_test_split(X, y, test_size=0.3, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    test_split_size = int(len(X) * test_size)\n",
        "    test_indices = indices[:test_split_size]\n",
        "    train_indices = indices[test_split_size:]\n",
        "\n",
        "    X_train, X_test = X[train_indices], X[test_indices]\n",
        "    y_train, y_test = y[train_indices], y[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "K4nyGiSCCnW7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X, Y, W):\n",
        "    m = len(Y)\n",
        "    y_pred = np.dot(X, W)\n",
        "    cost = (1 / (2 * m)) * np.sum((y_pred - Y) ** 2)\n",
        "    return cost"
      ],
      "metadata": {
        "id": "W_R80eR-Crxz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    m = len(Y)\n",
        "    cost_history = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        Y_pred = np.dot(X, W)\n",
        "        loss = Y_pred - Y\n",
        "        dw = (1 / m) * np.dot(X.T, loss)\n",
        "        W = W - alpha * dw\n",
        "        cost = cost_function(X, Y, W)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return W, cost_history\n"
      ],
      "metadata": {
        "id": "whcm5AAgCxvb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y - Y_pred) ** 2))"
      ],
      "metadata": {
        "id": "FJ4K0raGC0_u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)"
      ],
      "metadata": {
        "id": "VXe30xY8C-pT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y - Y_pred) ** 2))\n",
        "\n",
        "\n",
        "def r2(Y, Y_pred):\n",
        "    mean_y = np.mean(Y)\n",
        "    ss_tot = np.sum((Y - mean_y) ** 2)\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Step 1: Load dataset\n",
        "    data = pd.read_csv('student.csv')\n",
        "\n",
        "    # Step 2: Features and Target\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # Step 3: Train-test split\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "        X, Y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Step 4: Initialize parameters\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.0001\n",
        "    iterations = 1000\n",
        "\n",
        "    # Step 5: Gradient Descent\n",
        "    W_optimal, cost_history = gradient_descent(\n",
        "        X_train, Y_train, W, alpha, iterations\n",
        "    )\n",
        "\n",
        "    # Step 6: Predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Step 7: Evaluation\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Step 8: Results\n",
        "    print(\"Final Weights:\", W_optimal)\n",
        "    print(\"Cost History (First 10):\", cost_history[:10])\n",
        "    print(\"RMSE on Test Set:\", model_rmse)\n",
        "    print(\"R-Squared on Test Set:\", model_r2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00asXrlNDAdM",
        "outputId": "4076555d-a43c-4aa4-d9eb-da80314fb266"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.0894932  0.89504864]\n",
            "Cost History (First 10): [np.float64(17.813797177522098), np.float64(16.983149024878305), np.float64(16.925140245010397), np.float64(16.867870818076216), np.float64(16.811093513105355), np.float64(16.754804026075387), np.float64(16.69899816573971), np.float64(16.64367177688582), np.float64(16.588820740001896), np.float64(16.53444097097003)]\n",
            "RMSE on Test Set: 4.792607360540954\n",
            "R-Squared on Test Set: 0.908240340333986\n"
          ]
        }
      ]
    }
  ]
}